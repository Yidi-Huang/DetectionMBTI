{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    GOLD EI NS FT PJ                                           vacances   \n",
      "0   INFP  I  N  F  P  J'aime beaucoup voyager (que cela soit en Fran...  \\\n",
      "1   ENFP  E  N  F  P  Je préfère les voyages de vacances non planifi...   \n",
      "2   INTJ  I  N  T  P  aller dans des endroits / lieux visuellement b...   \n",
      "3   INFJ  E  N  F  P  Partir dans un endroit que je ne connais pas, ...   \n",
      "4   INTP  I  N  T  P  Mon type de vacances préféré est lorsque je re...   \n",
      "..   ... .. .. .. ..                                                ...   \n",
      "60  ESTJ  E  S  T  J  Sortir avec des amis qui forment une équipe bi...   \n",
      "61  ENFJ  I  N  F  P  J’aime bien trouver des lieux pas très populai...   \n",
      "62  ISTP  E  S  F  P  J’aime bien les vacances chills. J’aime bien a...   \n",
      "63  ISTJ  I  S  T  J  Si j'ai plus ou moins un mois pour les vacance...   \n",
      "64  INFP  I  N  F  P  Partir en vacances avec quelques amis, dans un...   \n",
      "\n",
      "                                          Passe-temps  \n",
      "0   J'aime beaucoup écrire, apprendre des langues ...  \n",
      "1   Mes activités préférées sont la danse et le vi...  \n",
      "2   me promener dans Paris, faire les magasins, tr...  \n",
      "3   - les travaux manuels : acquérir une compétenc...  \n",
      "4   J'apprécie énormément découvrir (et donc regar...  \n",
      "..                                                ...  \n",
      "60  Rester chez moi quand je suis fatiguée, sinon ...  \n",
      "61  Les vacances à l’étranger, un lieu personne ne...  \n",
      "62  Normalement j’aime bien rester à la maison et ...  \n",
      "63  Je vais rester à la maison pour écouter de la ...  \n",
      "64  Je préfère écouter de la musique, lire, jouer ...  \n",
      "\n",
      "[65 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('annote_yidi.csv')\n",
    "\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Précision, rappel, F-mesure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_performance_metrics(csv_filename, label_column, positive_label):\n",
    "    # 读取数据\n",
    "    df = pd.read_csv(csv_filename)\n",
    "\n",
    "    # 提取真实标签和预测标签\n",
    "    true_labels = [label[0] for label in df['GOLD']]\n",
    "    predicted_labels = df[label_column]\n",
    "\n",
    "    # 计算混淆矩阵\n",
    "    confusion_matrix_result = confusion_matrix(true_labels, predicted_labels, labels=[positive_label])\n",
    "\n",
    "    # 计算精确性、召回率和 F1 分数\n",
    "    precision = precision_score(true_labels, predicted_labels, pos_label=positive_label)\n",
    "    recall = recall_score(true_labels, predicted_labels, pos_label=positive_label)\n",
    "    f1 = f1_score(true_labels, predicted_labels, pos_label=positive_label)\n",
    "\n",
    "    return confusion_matrix_result, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "混淆矩阵 (EI):\n",
      "[[18]]\n",
      "精确性 (EI): 0.8571428571428571\n",
      "召回率 (EI): 0.6666666666666666\n",
      "F1 分数 (EI): 0.75\n"
     ]
    }
   ],
   "source": [
    "# 调用函数并打印结果\n",
    "csv_filename = 'annote_yidi.csv'\n",
    "label_column = 'EI'\n",
    "positive_label = 'E'\n",
    "\n",
    "confusion_matrix_result, precision, recall, f1 = calculate_performance_metrics(csv_filename, label_column, positive_label)\n",
    "\n",
    "print(f\"混淆矩阵 ({label_column}):\\n{confusion_matrix_result}\")\n",
    "print(f\"精确性 ({label_column}): {precision}\")\n",
    "print(f\"召回率 ({label_column}): {recall}\")\n",
    "print(f\"F1 分数 ({label_column}): {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "混淆矩阵 (EI):\n",
      "[[35]]\n",
      "精确性 (EI): 0.7954545454545454\n",
      "召回率 (EI): 0.9210526315789473\n",
      "F1 分数 (EI): 0.8536585365853658\n"
     ]
    }
   ],
   "source": [
    "# 调用函数并打印结果\n",
    "csv_filename = 'annote_yidi.csv'\n",
    "label_column = 'EI'\n",
    "positive_label = 'I'\n",
    "\n",
    "confusion_matrix_result, precision, recall, f1 = calculate_performance_metrics(csv_filename, label_column, positive_label)\n",
    "\n",
    "print(f\"混淆矩阵 ({label_column}):\\n{confusion_matrix_result}\")\n",
    "print(f\"精确性 ({label_column}): {precision}\")\n",
    "print(f\"召回率 ({label_column}): {recall}\")\n",
    "print(f\"F1 分数 ({label_column}): {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "混淆矩阵 (EI):\n",
      "[[12]]\n",
      "精确性 (EI): 1.0\n",
      "召回率 (EI): 0.4444444444444444\n",
      "F1 分数 (EI): 0.6153846153846153\n"
     ]
    }
   ],
   "source": [
    "csv_filename = 'annote_kexin.csv'\n",
    "label_column = 'EI'\n",
    "positive_label = 'E'\n",
    "\n",
    "confusion_matrix_result, precision, recall, f1 = calculate_performance_metrics(csv_filename, label_column, positive_label)\n",
    "\n",
    "print(f\"混淆矩阵 ({label_column}):\\n{confusion_matrix_result}\")\n",
    "print(f\"精确性 ({label_column}): {precision}\")\n",
    "print(f\"召回率 ({label_column}): {recall}\")\n",
    "print(f\"F1 分数 ({label_column}): {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "混淆矩阵 (EI):\n",
      "[[38]]\n",
      "精确性 (EI): 0.7169811320754716\n",
      "召回率 (EI): 1.0\n",
      "F1 分数 (EI): 0.8351648351648352\n"
     ]
    }
   ],
   "source": [
    "csv_filename = 'annote_kexin.csv'\n",
    "label_column = 'EI'\n",
    "positive_label = 'I'\n",
    "\n",
    "confusion_matrix_result, precision, recall, f1 = calculate_performance_metrics(csv_filename, label_column, positive_label)\n",
    "\n",
    "print(f\"混淆矩阵 ({label_column}):\\n{confusion_matrix_result}\")\n",
    "print(f\"精确性 ({label_column}): {precision}\")\n",
    "print(f\"召回率 ({label_column}): {recall}\")\n",
    "print(f\"F1 分数 ({label_column}): {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_performance_metrics(csv_filename, label_column, positive_label):\n",
    "    # 读取数据\n",
    "    df = pd.read_csv(csv_filename)\n",
    "\n",
    "    # 提取真实标签和预测标签\n",
    "    true_labels = [label[1] for label in df['GOLD']]\n",
    "    predicted_labels = df[label_column]\n",
    "\n",
    "    # 计算混淆矩阵\n",
    "    confusion_matrix_result = confusion_matrix(true_labels, predicted_labels, labels=[positive_label])\n",
    "\n",
    "    # 计算精确性、召回率和 F1 分数\n",
    "    precision = precision_score(true_labels, predicted_labels, pos_label=positive_label)\n",
    "    recall = recall_score(true_labels, predicted_labels, pos_label=positive_label)\n",
    "    f1 = f1_score(true_labels, predicted_labels, pos_label=positive_label)\n",
    "\n",
    "    return confusion_matrix_result, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "混淆矩阵 (NS):\n",
      "[[47]]\n",
      "精确性 (NS): 0.9038461538461539\n",
      "召回率 (NS): 0.9215686274509803\n",
      "F1 分数 (NS): 0.9126213592233009\n"
     ]
    }
   ],
   "source": [
    "# 调用函数并打印结果\n",
    "csv_filename = 'annote_yidi.csv'\n",
    "label_column = 'NS'\n",
    "positive_label = 'N'\n",
    "\n",
    "confusion_matrix_result, precision, recall, f1 = calculate_performance_metrics(csv_filename, label_column, positive_label)\n",
    "\n",
    "print(f\"混淆矩阵 ({label_column}):\\n{confusion_matrix_result}\")\n",
    "print(f\"精确性 ({label_column}): {precision}\")\n",
    "print(f\"召回率 ({label_column}): {recall}\")\n",
    "print(f\"F1 分数 ({label_column}): {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "混淆矩阵 (NS):\n",
      "[[9]]\n",
      "精确性 (NS): 0.6923076923076923\n",
      "召回率 (NS): 0.6428571428571429\n",
      "F1 分数 (NS): 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# 调用函数并打印结果\n",
    "csv_filename = 'annote_yidi.csv'\n",
    "label_column = 'NS'\n",
    "positive_label = 'S'\n",
    "\n",
    "confusion_matrix_result, precision, recall, f1 = calculate_performance_metrics(csv_filename, label_column, positive_label)\n",
    "\n",
    "print(f\"混淆矩阵 ({label_column}):\\n{confusion_matrix_result}\")\n",
    "print(f\"精确性 ({label_column}): {precision}\")\n",
    "print(f\"召回率 ({label_column}): {recall}\")\n",
    "print(f\"F1 分数 ({label_column}): {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "混淆矩阵 (NS):\n",
      "[[46]]\n",
      "精确性 (NS): 0.92\n",
      "召回率 (NS): 0.9019607843137255\n",
      "F1 分数 (NS): 0.9108910891089109\n"
     ]
    }
   ],
   "source": [
    "# 调用函数并打印结果\n",
    "csv_filename = 'annote_kexin.csv'\n",
    "label_column = 'NS'\n",
    "positive_label = 'N'\n",
    "\n",
    "confusion_matrix_result, precision, recall, f1 = calculate_performance_metrics(csv_filename, label_column, positive_label)\n",
    "\n",
    "print(f\"混淆矩阵 ({label_column}):\\n{confusion_matrix_result}\")\n",
    "print(f\"精确性 ({label_column}): {precision}\")\n",
    "print(f\"召回率 ({label_column}): {recall}\")\n",
    "print(f\"F1 分数 ({label_column}): {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "混淆矩阵 (NS):\n",
      "[[10]]\n",
      "精确性 (NS): 0.6666666666666666\n",
      "召回率 (NS): 0.7142857142857143\n",
      "F1 分数 (NS): 0.689655172413793\n"
     ]
    }
   ],
   "source": [
    "# 调用函数并打印结果\n",
    "csv_filename = 'annote_kexin.csv'\n",
    "label_column = 'NS'\n",
    "positive_label = 'S'\n",
    "\n",
    "confusion_matrix_result, precision, recall, f1 = calculate_performance_metrics(csv_filename, label_column, positive_label)\n",
    "\n",
    "print(f\"混淆矩阵 ({label_column}):\\n{confusion_matrix_result}\")\n",
    "print(f\"精确性 ({label_column}): {precision}\")\n",
    "print(f\"召回率 ({label_column}): {recall}\")\n",
    "print(f\"F1 分数 ({label_column}): {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_performance_metrics(csv_filename, label_column, positive_label):\n",
    "    # 读取数据\n",
    "    df = pd.read_csv(csv_filename)\n",
    "\n",
    "    # 提取真实标签和预测标签\n",
    "    true_labels = [label[2] for label in df['GOLD']]\n",
    "    predicted_labels = df[label_column]\n",
    "\n",
    "    # 计算混淆矩阵\n",
    "    confusion_matrix_result = confusion_matrix(true_labels, predicted_labels, labels=[positive_label])\n",
    "\n",
    "    # 计算精确性、召回率和 F1 分数\n",
    "    precision = precision_score(true_labels, predicted_labels, pos_label=positive_label)\n",
    "    recall = recall_score(true_labels, predicted_labels, pos_label=positive_label)\n",
    "    f1 = f1_score(true_labels, predicted_labels, pos_label=positive_label)\n",
    "\n",
    "    return confusion_matrix_result, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "混淆矩阵 (FT):\n",
      "[[37]]\n",
      "精确性 (FT): 0.8604651162790697\n",
      "召回率 (FT): 0.8604651162790697\n",
      "F1 分数 (FT): 0.8604651162790697\n"
     ]
    }
   ],
   "source": [
    "# 调用函数并打印结果\n",
    "csv_filename = 'annote_yidi.csv'\n",
    "label_column = 'FT'\n",
    "positive_label = 'F'\n",
    "\n",
    "confusion_matrix_result, precision, recall, f1 = calculate_performance_metrics(csv_filename, label_column, positive_label)\n",
    "\n",
    "print(f\"混淆矩阵 ({label_column}):\\n{confusion_matrix_result}\")\n",
    "print(f\"精确性 ({label_column}): {precision}\")\n",
    "print(f\"召回率 ({label_column}): {recall}\")\n",
    "print(f\"F1 分数 ({label_column}): {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "混淆矩阵 (FT):\n",
      "[[16]]\n",
      "精确性 (FT): 0.7272727272727273\n",
      "召回率 (FT): 0.7272727272727273\n",
      "F1 分数 (FT): 0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "# 调用函数并打印结果\n",
    "csv_filename = 'annote_yidi.csv'\n",
    "label_column = 'FT'\n",
    "positive_label = 'T'\n",
    "\n",
    "confusion_matrix_result, precision, recall, f1 = calculate_performance_metrics(csv_filename, label_column, positive_label)\n",
    "\n",
    "print(f\"混淆矩阵 ({label_column}):\\n{confusion_matrix_result}\")\n",
    "print(f\"精确性 ({label_column}): {precision}\")\n",
    "print(f\"召回率 ({label_column}): {recall}\")\n",
    "print(f\"F1 分数 ({label_column}): {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "混淆矩阵 (FT):\n",
      "[[39]]\n",
      "精确性 (FT): 0.8666666666666667\n",
      "召回率 (FT): 0.9069767441860465\n",
      "F1 分数 (FT): 0.8863636363636364\n"
     ]
    }
   ],
   "source": [
    "# 调用函数并打印结果\n",
    "csv_filename = 'annote_kexin.csv'\n",
    "label_column = 'FT'\n",
    "positive_label = 'F'\n",
    "\n",
    "confusion_matrix_result, precision, recall, f1 = calculate_performance_metrics(csv_filename, label_column, positive_label)\n",
    "\n",
    "print(f\"混淆矩阵 ({label_column}):\\n{confusion_matrix_result}\")\n",
    "print(f\"精确性 ({label_column}): {precision}\")\n",
    "print(f\"召回率 ({label_column}): {recall}\")\n",
    "print(f\"F1 分数 ({label_column}): {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "混淆矩阵 (FT):\n",
      "[[16]]\n",
      "精确性 (FT): 0.8\n",
      "召回率 (FT): 0.7272727272727273\n",
      "F1 分数 (FT): 0.761904761904762\n"
     ]
    }
   ],
   "source": [
    "# 调用函数并打印结果\n",
    "csv_filename = 'annote_kexin.csv'\n",
    "label_column = 'FT'\n",
    "positive_label = 'T'\n",
    "\n",
    "confusion_matrix_result, precision, recall, f1 = calculate_performance_metrics(csv_filename, label_column, positive_label)\n",
    "\n",
    "print(f\"混淆矩阵 ({label_column}):\\n{confusion_matrix_result}\")\n",
    "print(f\"精确性 ({label_column}): {precision}\")\n",
    "print(f\"召回率 ({label_column}): {recall}\")\n",
    "print(f\"F1 分数 ({label_column}): {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_performance_metrics(csv_filename, label_column, positive_label):\n",
    "    # 读取数据\n",
    "    df = pd.read_csv(csv_filename)\n",
    "\n",
    "    # 提取真实标签和预测标签\n",
    "    true_labels = [label[3] for label in df['GOLD']]\n",
    "    predicted_labels = df[label_column]\n",
    "\n",
    "    # 计算混淆矩阵\n",
    "    confusion_matrix_result = confusion_matrix(true_labels, predicted_labels, labels=[positive_label])\n",
    "\n",
    "    # 计算精确性、召回率和 F1 分数\n",
    "    precision = precision_score(true_labels, predicted_labels, pos_label=positive_label)\n",
    "    recall = recall_score(true_labels, predicted_labels, pos_label=positive_label)\n",
    "    f1 = f1_score(true_labels, predicted_labels, pos_label=positive_label)\n",
    "   \n",
    "\n",
    "    return confusion_matrix_result, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "混淆矩阵 (PJ):\n",
      "[[26]]\n",
      "精确性 (PJ): 0.5909090909090909\n",
      "召回率 (PJ): 0.8125\n",
      "F1 分数 (PJ): 0.6842105263157896\n"
     ]
    }
   ],
   "source": [
    "# 调用函数并打印结果\n",
    "csv_filename = 'annote_yidi.csv'\n",
    "label_column = 'PJ'\n",
    "positive_label = 'P'\n",
    "\n",
    "confusion_matrix_result, precision, recall, f1 = calculate_performance_metrics(csv_filename, label_column, positive_label)\n",
    "\n",
    "print(f\"混淆矩阵 ({label_column}):\\n{confusion_matrix_result}\")\n",
    "print(f\"精确性 ({label_column}): {precision}\")\n",
    "print(f\"召回率 ({label_column}): {recall}\")\n",
    "print(f\"F1 分数 ({label_column}): {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "混淆矩阵 (PJ):\n",
      "[[15]]\n",
      "精确性 (PJ): 0.7142857142857143\n",
      "召回率 (PJ): 0.45454545454545453\n",
      "F1 分数 (PJ): 0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "# 调用函数并打印结果\n",
    "csv_filename = 'annote_yidi.csv'\n",
    "label_column = 'PJ'\n",
    "positive_label = 'J'\n",
    "\n",
    "confusion_matrix_result, precision, recall, f1 = calculate_performance_metrics(csv_filename, label_column, positive_label)\n",
    "\n",
    "print(f\"混淆矩阵 ({label_column}):\\n{confusion_matrix_result}\")\n",
    "print(f\"精确性 ({label_column}): {precision}\")\n",
    "print(f\"召回率 ({label_column}): {recall}\")\n",
    "print(f\"F1 分数 ({label_column}): {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performance_metrics(csv_filename, label_column, positive_label):\n",
    "    # 读取数据\n",
    "    df = pd.read_csv(csv_filename)\n",
    "\n",
    "    # 提取真实标签和预测标签\n",
    "    true_labels = [label[3] for label in df['GOLD']]\n",
    "    predicted_labels = df[label_column]\n",
    "\n",
    "    # 计算混淆矩阵\n",
    "    confusion_matrix_result = confusion_matrix(true_labels, predicted_labels, labels=[positive_label])\n",
    "\n",
    "    if confusion_matrix_result.shape != (2, 2):\n",
    "        raise ValueError(\"混淆矩阵不是2x2的矩阵\")\n",
    "\n",
    "    # 计算精确性、召回率和 F1 分数\n",
    "    precision = precision_score(true_labels, predicted_labels, pos_label=positive_label)\n",
    "    recall = recall_score(true_labels, predicted_labels, pos_label=positive_label)\n",
    "    f1 = f1_score(true_labels, predicted_labels, pos_label=positive_label)\n",
    "\n",
    "    return confusion_matrix_result, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "混淆矩阵不是2x2的矩阵",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/kexingui/M2/Iris_cours_projet/Git_groupe/Modelisation_MBTI/Resultat_kexin.ipynb 单元格 26\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kexingui/M2/Iris_cours_projet/Git_groupe/Modelisation_MBTI/Resultat_kexin.ipynb#X35sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m label_column \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mPJ\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kexingui/M2/Iris_cours_projet/Git_groupe/Modelisation_MBTI/Resultat_kexin.ipynb#X35sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m positive_label \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mJ\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kexingui/M2/Iris_cours_projet/Git_groupe/Modelisation_MBTI/Resultat_kexin.ipynb#X35sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m confusion_matrix_result, precision, recall, f1 \u001b[39m=\u001b[39m calculate_performance_metrics(csv_filename, label_column, positive_label)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kexingui/M2/Iris_cours_projet/Git_groupe/Modelisation_MBTI/Resultat_kexin.ipynb#X35sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# 打印混淆矩阵\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kexingui/M2/Iris_cours_projet/Git_groupe/Modelisation_MBTI/Resultat_kexin.ipynb#X35sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m混淆矩阵 (\u001b[39m\u001b[39m{\u001b[39;00mlabel_column\u001b[39m}\u001b[39;00m\u001b[39m):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mconfusion_matrix_result[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mconfusion_matrix_result[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/Users/kexingui/M2/Iris_cours_projet/Git_groupe/Modelisation_MBTI/Resultat_kexin.ipynb 单元格 26\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kexingui/M2/Iris_cours_projet/Git_groupe/Modelisation_MBTI/Resultat_kexin.ipynb#X35sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m confusion_matrix_result \u001b[39m=\u001b[39m confusion_matrix(true_labels, predicted_labels, labels\u001b[39m=\u001b[39m[positive_label])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kexingui/M2/Iris_cours_projet/Git_groupe/Modelisation_MBTI/Resultat_kexin.ipynb#X35sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mif\u001b[39;00m confusion_matrix_result\u001b[39m.\u001b[39mshape \u001b[39m!=\u001b[39m (\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kexingui/M2/Iris_cours_projet/Git_groupe/Modelisation_MBTI/Resultat_kexin.ipynb#X35sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m混淆矩阵不是2x2的矩阵\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kexingui/M2/Iris_cours_projet/Git_groupe/Modelisation_MBTI/Resultat_kexin.ipynb#X35sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# 计算精确性、召回率和 F1 分数\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kexingui/M2/Iris_cours_projet/Git_groupe/Modelisation_MBTI/Resultat_kexin.ipynb#X35sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m precision \u001b[39m=\u001b[39m precision_score(true_labels, predicted_labels, pos_label\u001b[39m=\u001b[39mpositive_label)\n",
      "\u001b[0;31mValueError\u001b[0m: 混淆矩阵不是2x2的矩阵"
     ]
    }
   ],
   "source": [
    "# 调用函数并打印结果\n",
    "csv_filename = 'annote_yidi.csv'\n",
    "label_column = 'PJ'\n",
    "positive_label = 'J'\n",
    "\n",
    "confusion_matrix_result, precision, recall, f1 = calculate_performance_metrics(csv_filename, label_column, positive_label)\n",
    "\n",
    "# 打印混淆矩阵\n",
    "print(f\"混淆矩阵 ({label_column}):\\n{confusion_matrix_result[0]} {confusion_matrix_result[1]}\")\n",
    "print(f\"精确性 ({label_column}): {precision}\")\n",
    "print(f\"召回率 ({label_column}): {recall}\")\n",
    "print(f\"F1 分数 ({label_column}): {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/kexingui/M2/Iris_cours_projet/Git_groupe/Modelisation_MBTI/Untitled-2.ipynb 单元格 26\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kexingui/M2/Iris_cours_projet/Git_groupe/Modelisation_MBTI/Untitled-2.ipynb#X65sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m label_column \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mPJ\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kexingui/M2/Iris_cours_projet/Git_groupe/Modelisation_MBTI/Untitled-2.ipynb#X65sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m positive_label \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mP\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kexingui/M2/Iris_cours_projet/Git_groupe/Modelisation_MBTI/Untitled-2.ipynb#X65sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m confusion_matrix_result, precision, recall, f1 \u001b[39m=\u001b[39m calculate_performance_metrics(csv_filename, label_column, positive_label)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kexingui/M2/Iris_cours_projet/Git_groupe/Modelisation_MBTI/Untitled-2.ipynb#X65sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m混淆矩阵 (\u001b[39m\u001b[39m{\u001b[39;00mlabel_column\u001b[39m}\u001b[39;00m\u001b[39m):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mconfusion_matrix_result\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kexingui/M2/Iris_cours_projet/Git_groupe/Modelisation_MBTI/Untitled-2.ipynb#X65sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m精确性 (\u001b[39m\u001b[39m{\u001b[39;00mlabel_column\u001b[39m}\u001b[39;00m\u001b[39m): \u001b[39m\u001b[39m{\u001b[39;00mprecision\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/Users/kexingui/M2/Iris_cours_projet/Git_groupe/Modelisation_MBTI/Untitled-2.ipynb 单元格 26\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kexingui/M2/Iris_cours_projet/Git_groupe/Modelisation_MBTI/Untitled-2.ipynb#X65sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m confusion_matrix_result \u001b[39m=\u001b[39m confusion_matrix(true_labels, predicted_labels, labels\u001b[39m=\u001b[39m[positive_label])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kexingui/M2/Iris_cours_projet/Git_groupe/Modelisation_MBTI/Untitled-2.ipynb#X65sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# 计算精确性、召回率和 F1 分数\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kexingui/M2/Iris_cours_projet/Git_groupe/Modelisation_MBTI/Untitled-2.ipynb#X65sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m precision \u001b[39m=\u001b[39m precision_score(true_labels, predicted_labels, pos_label\u001b[39m=\u001b[39;49mpositive_label)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kexingui/M2/Iris_cours_projet/Git_groupe/Modelisation_MBTI/Untitled-2.ipynb#X65sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m recall \u001b[39m=\u001b[39m recall_score(true_labels, predicted_labels, pos_label\u001b[39m=\u001b[39mpositive_label)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kexingui/M2/Iris_cours_projet/Git_groupe/Modelisation_MBTI/Untitled-2.ipynb#X65sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m f1 \u001b[39m=\u001b[39m f1_score(true_labels, predicted_labels, pos_label\u001b[39m=\u001b[39mpositive_label)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1954\u001b[0m, in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1825\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprecision_score\u001b[39m(\n\u001b[1;32m   1826\u001b[0m     y_true,\n\u001b[1;32m   1827\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1833\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1834\u001b[0m ):\n\u001b[1;32m   1835\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the precision.\u001b[39;00m\n\u001b[1;32m   1836\u001b[0m \n\u001b[1;32m   1837\u001b[0m \u001b[39m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1952\u001b[0m \u001b[39m    array([0.5, 1. , 1. ])\u001b[39;00m\n\u001b[1;32m   1953\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1954\u001b[0m     p, _, _, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[1;32m   1955\u001b[0m         y_true,\n\u001b[1;32m   1956\u001b[0m         y_pred,\n\u001b[1;32m   1957\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   1958\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[1;32m   1959\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[1;32m   1960\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mprecision\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[1;32m   1961\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1962\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[1;32m   1963\u001b[0m     )\n\u001b[1;32m   1964\u001b[0m     \u001b[39mreturn\u001b[39;00m p\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1573\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[39mif\u001b[39;00m beta \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1572\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mbeta should be >=0 in the F-beta score\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1573\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[1;32m   1575\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1576\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1391\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1389\u001b[0m         \u001b[39mif\u001b[39;00m y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1390\u001b[0m             average_options\u001b[39m.\u001b[39mremove(\u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1391\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1392\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mTarget is \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m but average=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. Please \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1393\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mchoose another average setting, one of \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (y_type, average_options)\n\u001b[1;32m   1394\u001b[0m         )\n\u001b[1;32m   1395\u001b[0m \u001b[39melif\u001b[39;00m pos_label \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mNone\u001b[39;00m, \u001b[39m1\u001b[39m):\n\u001b[1;32m   1396\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1397\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNote that pos_label (set to \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m) is ignored when \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39maverage != \u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m'\u001b[39m\u001b[39m (got \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m). You may use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1401\u001b[0m         \u001b[39mUserWarning\u001b[39;00m,\n\u001b[1;32m   1402\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "# 调用函数并打印结果\n",
    "csv_filename = 'annote_kexin.csv'\n",
    "label_column = 'PJ'\n",
    "positive_label = 'P'\n",
    "\n",
    "confusion_matrix_result, precision, recall, f1 = calculate_performance_metrics(csv_filename, label_column, positive_label)\n",
    "\n",
    "print(f\"混淆矩阵 ({label_column}):\\n{confusion_matrix_result}\")\n",
    "print(f\"精确性 ({label_column}): {precision}\")\n",
    "print(f\"召回率 ({label_column}): {recall}\")\n",
    "print(f\"F1 分数 ({label_column}): {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
